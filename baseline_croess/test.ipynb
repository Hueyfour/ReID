{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import pretrainedmodels\n",
    "import tensorwatch as tw\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/yxy/ReID/data/DukeMTMC-reID/pytorch/\"\n",
    "\n",
    "galleryset = datasets.ImageFolder(os.path.join(data_dir, 'gallery'),\n",
    "                                               transforms.Compose([\n",
    "                                                   transforms.Resize((256,128), interpolation=3),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "galleryloaders = torch.utils.data.DataLoader(galleryset, batch_size=32,\n",
    "                                             shuffle=False, num_workers=16) \n",
    "\n",
    "\n",
    "queryset = datasets.ImageFolder(os.path.join(data_dir, 'query'),\n",
    "                                               transforms.Compose([\n",
    "                                                   transforms.Resize((256,128), interpolation=3),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "queryloaders = torch.utils.data.DataLoader(queryset, batch_size=32,\n",
    "                                             shuffle=False, num_workers=16) \n",
    "\n",
    "#multiqueryset = datasets.ImageFolder(os.path.join(data_dir, 'multi-query'),\n",
    "#                                               transforms.Compose([\n",
    "#                                                   transforms.Resize((256,128), interpolation=3),\n",
    "#                                                   transforms.ToTensor(),\n",
    "#                                                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#                                               ]))\n",
    "#multiqueryloaders = torch.utils.data.DataLoader(multiqueryset, batch_size=32,\n",
    "#                                             shuffle=False, num_workers=16) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17661\n",
      "2228\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6d06329e80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6d062d76a0>\n"
     ]
    }
   ],
   "source": [
    "print(len(galleryset))\n",
    "print(len(queryset))\n",
    "#print(len(multiqueryset))\n",
    "print(galleryloaders)\n",
    "print(queryloaders)\n",
    "#print(galleryset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in') # For old pytorch, you may use kaiming_normal.\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, std=0.001)\n",
    "        init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x,f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ft_net(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2):\n",
    "        super(ft_net, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.model = model_ft\n",
    "        self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(network):\n",
    "    save_path = os.path.join('./duke/model/resnet-duke.pth')\n",
    "    network.load_state_dict(torch.load(save_path))\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(img_path):\n",
    "    camera_id = []\n",
    "    labels = []\n",
    "    for path, v in img_path:\n",
    "        #filename = path.split('/')[-1]\n",
    "        filename = os.path.basename(path)\n",
    "        label = filename[0:4]\n",
    "        camera = filename.split('c')[1]\n",
    "        if label[0:2]=='-1':\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(int(label))\n",
    "        camera_id.append(int(camera[0]))\n",
    "    return camera_id, labels\n",
    "\n",
    "gallery_path = galleryset.imgs\n",
    "query_path = queryset.imgs\n",
    "#mquery_path = multiqueryset.imgs\n",
    "\n",
    "gallery_cam,gallery_label = get_id(gallery_path)\n",
    "query_cam,query_label = get_id(query_path)\n",
    "#mquery_cam,mquery_label = get_id(mquery_path)\n",
    "#print(gallery_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ft_net(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (classifier): ClassBlock(\n",
       "    (add_block): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.5)\n",
       "    )\n",
       "    (classifier): Sequential()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_structure = ft_net(702, stride = 2)\n",
    "model = load_network(model_structure)\n",
    "model.classifier.classifier = nn.Sequential()\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "model\n",
    "#tw.draw_model(model,[32, 3, 256, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliplr(img):\n",
    "    \"\"\"水平翻转\"\"\"\n",
    "    inv_idx = torch.arange(img.size(3)-1,-1,-1).long()\n",
    "    img_filp = img.index_select(3,inv_idx)    \n",
    "    return img_filp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "count = 0\n",
    "features = torch.FloatTensor()\n",
    "it = iter(galleryloaders)\n",
    "batch = next(it)\n",
    "img,labels = batch\n",
    "print(labels)\n",
    "print(img.size())\n",
    "n,c,h,w = img.size()\n",
    "count += n\n",
    "print(count)\n",
    "ff = torch.FloatTensor(n,512).zero_().to(device)\n",
    "#print(ff)\n",
    "input_img = img.to(device)\n",
    "#print(input_img)\n",
    "output = model(input_img)\n",
    "ff += output\n",
    "print(ff)\n",
    "\n",
    "fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n",
    "print(fnorm)\n",
    "ff = ff.div(fnorm.expand_as(ff))\n",
    "print(ff)\n",
    "print(ff.size())\n",
    "features = torch.cat((features,ff.data.cpu()), 0)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, dataloaders):\n",
    "    count = 0\n",
    "    features = torch.FloatTensor()\n",
    "    for i,data in enumerate(dataloaders):\n",
    "        img,labels = data\n",
    "        #print(img.size())\n",
    "        n,c,h,w = img.size()   \n",
    "        count += n\n",
    "        print(count)\n",
    "        ff = torch.FloatTensor(n,512).zero_().to(device)\n",
    "    \n",
    "        for i in range(2):\n",
    "            #if (i==1):\n",
    "                #img = fliplr(img)\n",
    "            input_img = img.to(device)\n",
    "            outputs = model(input_img)\n",
    "            \n",
    "            ff += outputs\n",
    "        \n",
    "        fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n",
    "        ff = ff.div(fnorm.expand_as(ff))\n",
    "        \n",
    "        features = torch.cat((features, ff.data.cpu()),0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2240\n",
      "2272\n",
      "2304\n",
      "2336\n",
      "2368\n",
      "2400\n",
      "2432\n",
      "2464\n",
      "2496\n",
      "2528\n",
      "2560\n",
      "2592\n",
      "2624\n",
      "2656\n",
      "2688\n",
      "2720\n",
      "2752\n",
      "2784\n",
      "2816\n",
      "2848\n",
      "2880\n",
      "2912\n",
      "2944\n",
      "2976\n",
      "3008\n",
      "3040\n",
      "3072\n",
      "3104\n",
      "3136\n",
      "3168\n",
      "3200\n",
      "3232\n",
      "3264\n",
      "3296\n",
      "3328\n",
      "3360\n",
      "3392\n",
      "3424\n",
      "3456\n",
      "3488\n",
      "3520\n",
      "3552\n",
      "3584\n",
      "3616\n",
      "3648\n",
      "3680\n",
      "3712\n",
      "3744\n",
      "3776\n",
      "3808\n",
      "3840\n",
      "3872\n",
      "3904\n",
      "3936\n",
      "3968\n",
      "4000\n",
      "4032\n",
      "4064\n",
      "4096\n",
      "4128\n",
      "4160\n",
      "4192\n",
      "4224\n",
      "4256\n",
      "4288\n",
      "4320\n",
      "4352\n",
      "4384\n",
      "4416\n",
      "4448\n",
      "4480\n",
      "4512\n",
      "4544\n",
      "4576\n",
      "4608\n",
      "4640\n",
      "4672\n",
      "4704\n",
      "4736\n",
      "4768\n",
      "4800\n",
      "4832\n",
      "4864\n",
      "4896\n",
      "4928\n",
      "4960\n",
      "4992\n",
      "5024\n",
      "5056\n",
      "5088\n",
      "5120\n",
      "5152\n",
      "5184\n",
      "5216\n",
      "5248\n",
      "5280\n",
      "5312\n",
      "5344\n",
      "5376\n",
      "5408\n",
      "5440\n",
      "5472\n",
      "5504\n",
      "5536\n",
      "5568\n",
      "5600\n",
      "5632\n",
      "5664\n",
      "5696\n",
      "5728\n",
      "5760\n",
      "5792\n",
      "5824\n",
      "5856\n",
      "5888\n",
      "5920\n",
      "5952\n",
      "5984\n",
      "6016\n",
      "6048\n",
      "6080\n",
      "6112\n",
      "6144\n",
      "6176\n",
      "6208\n",
      "6240\n",
      "6272\n",
      "6304\n",
      "6336\n",
      "6368\n",
      "6400\n",
      "6432\n",
      "6464\n",
      "6496\n",
      "6528\n",
      "6560\n",
      "6592\n",
      "6624\n",
      "6656\n",
      "6688\n",
      "6720\n",
      "6752\n",
      "6784\n",
      "6816\n",
      "6848\n",
      "6880\n",
      "6912\n",
      "6944\n",
      "6976\n",
      "7008\n",
      "7040\n",
      "7072\n",
      "7104\n",
      "7136\n",
      "7168\n",
      "7200\n",
      "7232\n",
      "7264\n",
      "7296\n",
      "7328\n",
      "7360\n",
      "7392\n",
      "7424\n",
      "7456\n",
      "7488\n",
      "7520\n",
      "7552\n",
      "7584\n",
      "7616\n",
      "7648\n",
      "7680\n",
      "7712\n",
      "7744\n",
      "7776\n",
      "7808\n",
      "7840\n",
      "7872\n",
      "7904\n",
      "7936\n",
      "7968\n",
      "8000\n",
      "8032\n",
      "8064\n",
      "8096\n",
      "8128\n",
      "8160\n",
      "8192\n",
      "8224\n",
      "8256\n",
      "8288\n",
      "8320\n",
      "8352\n",
      "8384\n",
      "8416\n",
      "8448\n",
      "8480\n",
      "8512\n",
      "8544\n",
      "8576\n",
      "8608\n",
      "8640\n",
      "8672\n",
      "8704\n",
      "8736\n",
      "8768\n",
      "8800\n",
      "8832\n",
      "8864\n",
      "8896\n",
      "8928\n",
      "8960\n",
      "8992\n",
      "9024\n",
      "9056\n",
      "9088\n",
      "9120\n",
      "9152\n",
      "9184\n",
      "9216\n",
      "9248\n",
      "9280\n",
      "9312\n",
      "9344\n",
      "9376\n",
      "9408\n",
      "9440\n",
      "9472\n",
      "9504\n",
      "9536\n",
      "9568\n",
      "9600\n",
      "9632\n",
      "9664\n",
      "9696\n",
      "9728\n",
      "9760\n",
      "9792\n",
      "9824\n",
      "9856\n",
      "9888\n",
      "9920\n",
      "9952\n",
      "9984\n",
      "10016\n",
      "10048\n",
      "10080\n",
      "10112\n",
      "10144\n",
      "10176\n",
      "10208\n",
      "10240\n",
      "10272\n",
      "10304\n",
      "10336\n",
      "10368\n",
      "10400\n",
      "10432\n",
      "10464\n",
      "10496\n",
      "10528\n",
      "10560\n",
      "10592\n",
      "10624\n",
      "10656\n",
      "10688\n",
      "10720\n",
      "10752\n",
      "10784\n",
      "10816\n",
      "10848\n",
      "10880\n",
      "10912\n",
      "10944\n",
      "10976\n",
      "11008\n",
      "11040\n",
      "11072\n",
      "11104\n",
      "11136\n",
      "11168\n",
      "11200\n",
      "11232\n",
      "11264\n",
      "11296\n",
      "11328\n",
      "11360\n",
      "11392\n",
      "11424\n",
      "11456\n",
      "11488\n",
      "11520\n",
      "11552\n",
      "11584\n",
      "11616\n",
      "11648\n",
      "11680\n",
      "11712\n",
      "11744\n",
      "11776\n",
      "11808\n",
      "11840\n",
      "11872\n",
      "11904\n",
      "11936\n",
      "11968\n",
      "12000\n",
      "12032\n",
      "12064\n",
      "12096\n",
      "12128\n",
      "12160\n",
      "12192\n",
      "12224\n",
      "12256\n",
      "12288\n",
      "12320\n",
      "12352\n",
      "12384\n",
      "12416\n",
      "12448\n",
      "12480\n",
      "12512\n",
      "12544\n",
      "12576\n",
      "12608\n",
      "12640\n",
      "12672\n",
      "12704\n",
      "12736\n",
      "12768\n",
      "12800\n",
      "12832\n",
      "12864\n",
      "12896\n",
      "12928\n",
      "12960\n",
      "12992\n",
      "13024\n",
      "13056\n",
      "13088\n",
      "13120\n",
      "13152\n",
      "13184\n",
      "13216\n",
      "13248\n",
      "13280\n",
      "13312\n",
      "13344\n",
      "13376\n",
      "13408\n",
      "13440\n",
      "13472\n",
      "13504\n",
      "13536\n",
      "13568\n",
      "13600\n",
      "13632\n",
      "13664\n",
      "13696\n",
      "13728\n",
      "13760\n",
      "13792\n",
      "13824\n",
      "13856\n",
      "13888\n",
      "13920\n",
      "13952\n",
      "13984\n",
      "14016\n",
      "14048\n",
      "14080\n",
      "14112\n",
      "14144\n",
      "14176\n",
      "14208\n",
      "14240\n",
      "14272\n",
      "14304\n",
      "14336\n",
      "14368\n",
      "14400\n",
      "14432\n",
      "14464\n",
      "14496\n",
      "14528\n",
      "14560\n",
      "14592\n",
      "14624\n",
      "14656\n",
      "14688\n",
      "14720\n",
      "14752\n",
      "14784\n",
      "14816\n",
      "14848\n",
      "14880\n",
      "14912\n",
      "14944\n",
      "14976\n",
      "15008\n",
      "15040\n",
      "15072\n",
      "15104\n",
      "15136\n",
      "15168\n",
      "15200\n",
      "15232\n",
      "15264\n",
      "15296\n",
      "15328\n",
      "15360\n",
      "15392\n",
      "15424\n",
      "15456\n",
      "15488\n",
      "15520\n",
      "15552\n",
      "15584\n",
      "15616\n",
      "15648\n",
      "15680\n",
      "15712\n",
      "15744\n",
      "15776\n",
      "15808\n",
      "15840\n",
      "15872\n",
      "15904\n",
      "15936\n",
      "15968\n",
      "16000\n",
      "16032\n",
      "16064\n",
      "16096\n",
      "16128\n",
      "16160\n",
      "16192\n",
      "16224\n",
      "16256\n",
      "16288\n",
      "16320\n",
      "16352\n",
      "16384\n",
      "16416\n",
      "16448\n",
      "16480\n",
      "16512\n",
      "16544\n",
      "16576\n",
      "16608\n",
      "16640\n",
      "16672\n",
      "16704\n",
      "16736\n",
      "16768\n",
      "16800\n",
      "16832\n",
      "16864\n",
      "16896\n",
      "16928\n",
      "16960\n",
      "16992\n",
      "17024\n",
      "17056\n",
      "17088\n",
      "17120\n",
      "17152\n",
      "17184\n",
      "17216\n",
      "17248\n",
      "17280\n",
      "17312\n",
      "17344\n",
      "17376\n",
      "17408\n",
      "17440\n",
      "17472\n",
      "17504\n",
      "17536\n",
      "17568\n",
      "17600\n",
      "17632\n",
      "17661\n",
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2228\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    gallery_feature = extract_feature(model,galleryloaders)\n",
    "    query_feature = extract_feature(model,queryloaders)\n",
    "#mquery_feature = extract_feature(model,multiqueryloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result ={ 'gallery_f':gallery_feature.numpy(),'gallery_label':gallery_label,'gallery_cam':gallery_cam,\n",
    "         'query_f':query_feature.numpy(),'query_label':query_label,'query_cam':query_cam}\n",
    "#result = {'mquery_f':mquery_feature.numpy(),'mquery_label':mquery_label,'mquery_cam':mquery_cam}\n",
    "scipy.io.savemat('./duke/pytorch_result.mat',result)\n",
    "#scipy.io.savemat('multi_query.mat',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
