{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from torch.nn import init\n",
    "import tensorwatch as tw\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/yxy/ReID/data/DukeMTMC-reID/pytorch/\"\n",
    "\n",
    "galleryset = datasets.ImageFolder(os.path.join(data_dir, 'gallery'),\n",
    "                                               transforms.Compose([\n",
    "                                                   transforms.Resize((256,128), interpolation=3),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "galleryloaders = torch.utils.data.DataLoader(galleryset, batch_size=32,\n",
    "                                             shuffle=False, num_workers=16) \n",
    "\n",
    "\n",
    "queryset = datasets.ImageFolder(os.path.join(data_dir, 'query'),\n",
    "                                               transforms.Compose([\n",
    "                                                   transforms.Resize((256,128), interpolation=3),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                               ]))\n",
    "queryloaders = torch.utils.data.DataLoader(queryset, batch_size=32,\n",
    "                                             shuffle=False, num_workers=16) \n",
    "\n",
    "#multiqueryset = datasets.ImageFolder(os.path.join(data_dir, 'multi-query'),\n",
    "#                                               transforms.Compose([\n",
    "#                                                   transforms.Resize((256,128), interpolation=3),\n",
    "#                                                   transforms.ToTensor(),\n",
    "#                                                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#                                               ]))\n",
    "#multiqueryloaders = torch.utils.data.DataLoader(multiqueryset, batch_size=32,\n",
    "#                                             shuffle=False, num_workers=16) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in') # For old pytorch, you may use kaiming_normal.\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, std=0.001)\n",
    "        init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x,f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ft_net(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2):\n",
    "        super(ft_net, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.model = model_ft\n",
    "        self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(network):\n",
    "    save_path = os.path.join('./model/resnet_croess.pth')\n",
    "    network.load_state_dict(torch.load(save_path))\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(img_path):\n",
    "    camera_id = []\n",
    "    labels = []\n",
    "    for path, v in img_path:\n",
    "        #filename = path.split('/')[-1]\n",
    "        filename = os.path.basename(path)\n",
    "        label = filename[0:4]\n",
    "        camera = filename.split('c')[1]\n",
    "        if label[0:2]=='-1':\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(int(label))\n",
    "        camera_id.append(int(camera[0]))\n",
    "    return camera_id, labels\n",
    "\n",
    "gallery_path = galleryset.imgs\n",
    "query_path = queryset.imgs\n",
    "#mquery_path = multiqueryset.imgs\n",
    "\n",
    "gallery_cam,gallery_label = get_id(gallery_path)\n",
    "query_cam,query_label = get_id(query_path)\n",
    "#mquery_cam,mquery_label = get_id(mquery_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_structure = ft_net(702, stride = 2)\n",
    "model = load_network(model_structure)\n",
    "model.classifier.classifier = nn.Sequential()\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliplr(img):\n",
    "    \"\"\"水平翻转\"\"\"\n",
    "    inv_idx = torch.arange(img.size(3)-1,-1,-1).long()\n",
    "    img_filp = img.index_select(3,inv_idx)    \n",
    "    return img_filp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, dataloaders):\n",
    "    count = 0\n",
    "    features = torch.FloatTensor()\n",
    "    print(\"start extract feature\")\n",
    "    for i,data in enumerate(dataloaders):\n",
    "        img,labels = data\n",
    "        n,c,h,w = img.size()   \n",
    "        count += n\n",
    "        ff = torch.FloatTensor(n,512).zero_().to(device)\n",
    "    \n",
    "        for i in range(2):\n",
    "            input_img = img.to(device)\n",
    "            outputs = model(input_img)\n",
    "            \n",
    "            ff += outputs\n",
    "        \n",
    "        fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n",
    "        ff = ff.div(fnorm.expand_as(ff))\n",
    "        \n",
    "        features = torch.cat((features, ff.data.cpu()),0)\n",
    "    print(\"extract feature finish\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start extract feature\n",
      "extract feature finish\n",
      "start extract feature\n",
      "extract feature finish\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    gallery_feature = extract_feature(model,galleryloaders)\n",
    "    query_feature = extract_feature(model,queryloaders)\n",
    "    #mquery_feature = extract_feature(model,multiqueryloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result ={ 'gallery_f':gallery_feature.numpy(),'gallery_label':gallery_label,'gallery_cam':gallery_cam,\n",
    "         'query_f':query_feature.numpy(),'query_label':query_label,'query_cam':query_cam}\n",
    "#result = {'mquery_f':mquery_feature.numpy(),'mquery_label':mquery_label,'mquery_cam':mquery_cam}\n",
    "\n",
    "scipy.io.savemat('./feature/pytorch_result.mat',result)\n",
    "#scipy.io.savemat('multi_query.mat',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
